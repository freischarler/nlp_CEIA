{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfa39F4lsLf3"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## LSTM Bot QA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqO0PRcFsPTe"
      },
      "source": [
        "### Datos\n",
        "El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n",
        "[LINK](http://convai.io/data/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bDFC0I3j9oFD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cq3YXak9sGHd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM, SimpleRNN\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHNkUaPp6aYq",
        "outputId": "4b85c75a-3d7a-4353-828b-f58e843a7c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El dataset ya se encuentra descargado\n"
          ]
        }
      ],
      "source": [
        "# Descargar la carpeta de dataset\n",
        "import os\n",
        "import gdown\n",
        "if os.access('data_volunteers.json', os.F_OK) is False:\n",
        "    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n",
        "    output = 'data_volunteers.json'\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"El dataset ya se encuentra descargado\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WZy1-wgG-Rp7"
      },
      "outputs": [],
      "source": [
        "# dataset_file\n",
        "import json\n",
        "\n",
        "text_file = \"data_volunteers.json\"\n",
        "with open(text_file) as f:\n",
        "    data = json.load(f) # la variable data será un diccionario\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue5qd54S-eew",
        "outputId": "2abf7c03-4dfc-4f2c-ca65-6ccb13f128ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Observar los campos disponibles en cada linea del dataset\n",
        "data[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHBRAXPl-3dz",
        "outputId": "4ef69238-3297-4684-b2fe-b2c129d47f66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de rows utilizadas: 6033\n"
          ]
        }
      ],
      "source": [
        "chat_in = []\n",
        "chat_out = []\n",
        "\n",
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "max_len = 30\n",
        "\n",
        "def clean_text(txt):\n",
        "    txt = txt.lower()\n",
        "    txt.replace(\"\\'d\", \" had\")\n",
        "    txt.replace(\"\\'s\", \" is\")\n",
        "    txt.replace(\"\\'m\", \" am\")\n",
        "    txt.replace(\"don't\", \"do not\")\n",
        "    txt = re.sub(r'\\W+', ' ', txt)\n",
        "\n",
        "    return txt\n",
        "\n",
        "for line in data:\n",
        "    for i in range(len(line['dialog'])-1):\n",
        "        # vamos separando el texto en \"preguntas\" (chat_in)\n",
        "        # y \"respuestas\" (chat_out)\n",
        "        chat_in = clean_text(line['dialog'][i]['text'])\n",
        "        chat_out = clean_text(line['dialog'][i+1]['text'])\n",
        "\n",
        "        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n",
        "            continue\n",
        "\n",
        "        input_sentence, output = chat_in, chat_out\n",
        "\n",
        "        # output sentence (decoder_output) tiene <eos>\n",
        "        output_sentence = output + ' <eos>'\n",
        "        # output sentence input (decoder_input) tiene <sos>\n",
        "        output_sentence_input = '<sos> ' + output\n",
        "\n",
        "        input_sentences.append(input_sentence)\n",
        "        output_sentences.append(output_sentence)\n",
        "        output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07L1qj8pC_l6",
        "outputId": "9c4dce15-7af0-430d-b691-8392f41777c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('hi how are you ', 'not bad and you  <eos>', '<sos> not bad and you ')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_sentences[1], output_sentences[1], output_sentences_inputs[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mALu6iuURJhs"
      },
      "source": [
        "### 2 - Preprocesamiento\n",
        "Realizar el preprocesamiento necesario para obtener:\n",
        "- word2idx_inputs, max_input_len\n",
        "- word2idx_outputs, max_out_len, num_words_output\n",
        "- encoder_input_sequences, decoder_output_sequences, decoder_targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG2XAGBVRKOJ",
        "outputId": "40ddeeb5-223a-4207-b45b-70f20899859b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabras en el vocabulario: 1799\n",
            "Sentencia de entrada más larga: 9\n"
          ]
        }
      ],
      "source": [
        "#Tamaño máximo del vocabulario\n",
        "MAX_VOCAB_SIZE = 8000\n",
        "\n",
        "# tokenizador de entrada\n",
        "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Sentencia de entrada más larga:\", max_input_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8axkrmTRaLJ",
        "outputId": "a85e62f1-de24-480e-d1d5-a2547af4480d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabras en el vocabulario: 1806\n",
            "Sentencia de entrada más larga: 10\n"
          ]
        }
      ],
      "source": [
        "# tokenizador de salida\n",
        "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
        "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
        "decoder_output_sequences = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "decoder_output_sequences_inputs = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
        "\n",
        "max_out_len = max(len(seq) for seq in decoder_output_sequences)\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "print(\"Sentencia de entrada más larga:\", max_out_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cLJIX1KR3d3",
        "outputId": "5208cd05-2a08-4d28-dee6-f02da097263f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de rows del dataset: 6033\n",
            "encoder_input_sequences shape: (6033, 9)\n",
            "decoder_input_sequences shape: (6033, 10)\n"
          ]
        }
      ],
      "source": [
        "#padding\n",
        "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
        "\n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
        "\n",
        "decoder_input_sequences = pad_sequences(decoder_output_sequences_inputs, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnOnjlhhSzua",
        "outputId": "2a45cd61-2a65-4bed-9757-74d9a6971e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "decoder_targets_sequences shape: (6033, 10, 1807)\n"
          ]
        }
      ],
      "source": [
        "decoder_output_sequences = pad_sequences(decoder_output_sequences, maxlen=max_out_len, padding='post')\n",
        "decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n",
        "print(\"decoder_targets_sequences shape:\",decoder_targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJIsLBbj6rg"
      },
      "source": [
        "### 3 - Preparar los embeddings\n",
        "Utilizar los embeddings de Glove o FastText para transformar los tokens de entrada en vectores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9a5uPd5T_Zc",
        "outputId": "7bc5da28-6dc9-4ef3-f90f-b2f2e8e02b61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: pybind11>=2.2 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from fasttext) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages (from fasttext) (75.1.0)\n",
            "Requirement already satisfied: numpy in c:\\python310\\lib\\site-packages (from fasttext) (1.26.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml): started\n",
            "  Building wheel for fasttext (pyproject.toml): finished with status 'error'\n",
            "Failed to build fasttext\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (c:\\users\\marti\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Building wheel for fasttext (pyproject.toml) did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [36 lines of output]\n",
            "      C:\\Users\\marti\\AppData\\Local\\Temp\\pip-build-env-pew43ul9\\overlay\\Lib\\site-packages\\setuptools\\dist.py:488: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
            "      !!\n",
            "      \n",
            "              ********************************************************************************\n",
            "              Usage of dash-separated 'description-file' will not be supported in future\n",
            "              versions. Please use the underscore name 'description_file' instead.\n",
            "      \n",
            "              By 2025-Mar-03, you need to update your project and remove deprecated calls\n",
            "              or your builds will no longer be supported.\n",
            "      \n",
            "              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
            "              ********************************************************************************\n",
            "      \n",
            "      !!\n",
            "        opt = self.warn_dash_deprecation(opt, section)\n",
            "      running bdist_wheel\n",
            "      running build\n",
            "      running build_py\n",
            "      creating build\\lib.win-amd64-cpython-310\\fasttext\n",
            "      copying python\\fasttext_module\\fasttext\\FastText.py -> build\\lib.win-amd64-cpython-310\\fasttext\n",
            "      copying python\\fasttext_module\\fasttext\\__init__.py -> build\\lib.win-amd64-cpython-310\\fasttext\n",
            "      creating build\\lib.win-amd64-cpython-310\\fasttext\\util\n",
            "      copying python\\fasttext_module\\fasttext\\util\\util.py -> build\\lib.win-amd64-cpython-310\\fasttext\\util\n",
            "      copying python\\fasttext_module\\fasttext\\util\\__init__.py -> build\\lib.win-amd64-cpython-310\\fasttext\\util\n",
            "      creating build\\lib.win-amd64-cpython-310\\fasttext\\tests\n",
            "      copying python\\fasttext_module\\fasttext\\tests\\test_configurations.py -> build\\lib.win-amd64-cpython-310\\fasttext\\tests\n",
            "      copying python\\fasttext_module\\fasttext\\tests\\test_script.py -> build\\lib.win-amd64-cpython-310\\fasttext\\tests\n",
            "      copying python\\fasttext_module\\fasttext\\tests\\__init__.py -> build\\lib.win-amd64-cpython-310\\fasttext\\tests\n",
            "      running build_ext\n",
            "      building 'fasttext_pybind' extension\n",
            "      creating build\\temp.win-amd64-cpython-310\\Release\\python\\fasttext_module\\fasttext\\pybind\n",
            "      creating build\\temp.win-amd64-cpython-310\\Release\\src\n",
            "      \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\marti\\AppData\\Local\\Temp\\pip-build-env-pew43ul9\\overlay\\Lib\\site-packages\\pybind11\\include -IC:\\Users\\marti\\AppData\\Local\\Temp\\pip-build-env-pew43ul9\\overlay\\Lib\\site-packages\\pybind11\\include -Isrc -IC:\\Python310\\include -IC:\\Python310\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /EHsc /Tppython/fasttext_module/fasttext/pybind/fasttext_pybind.cc /Fobuild\\temp.win-amd64-cpython-310\\Release\\python/fasttext_module/fasttext/pybind/fasttext_pybind.obj /EHsc /DVERSION_INFO=\\\\\\\"0.9.3\\\\\\\"\n",
            "      fasttext_pybind.cc\n",
            "      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\\Tools\\MSVC\\14.29.30133\\include\\yvals.h(12): fatal error C1083: Cannot open include file: 'crtdbg.h': No such file or directory\n",
            "      error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.29.30133\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for fasttext\n",
            "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (fasttext)\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext\n",
        "import fasttext.util\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SWxJl1hZeJWC",
        "outputId": "e99353bf-ae05-4968-9a88-494133b072dd"
      },
      "outputs": [],
      "source": [
        "#fasttext.util.download_model('en', if_exists='ignore')  # English\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "knwAO0_QniH3"
      },
      "outputs": [],
      "source": [
        "model_embeddings = fasttext.util.reduce_model(fasttext.load_model('cc.en.300.bin'), 100)\n",
        "#ft.get_dimension()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "qDOt39FLVcw2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preparing embedding matrix...\n",
            "1799\n",
            "number of null word embeddings: 1\n"
          ]
        }
      ],
      "source": [
        "print('preparing embedding matrix...')\n",
        "embed_dim = model_embeddings.get_dimension()\n",
        "words_not_found = []\n",
        "\n",
        "# word_index provieen del tokenizer\n",
        "\n",
        "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
        "#print (nb_words)\n",
        "\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word2idx_inputs.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    embedding_vector = model_embeddings.get_word_vector(word)\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        words_not_found.append(word)\n",
        "\n",
        "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix**2, axis=1) == 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1799, 100)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Índices inválidos en encoder_input_sequences: [6024]\n",
            "¡Error! Hay índices inválidos en encoder_input_sequences.\n",
            "Índices inválidos en decoder_input_sequences: []\n",
            "Todos los índices en decoder_input_sequences son válidos.\n",
            "Índices inválidos en decoder_targets: []\n",
            "Todos los índices en decoder_targets son válidos.\n"
          ]
        }
      ],
      "source": [
        "def check_indices(sequences, name, vocabulary_size):\n",
        "    print(f\"Índices inválidos en {name}: {invalid_indices[0]}\")\n",
        "    if len(invalid_indices[0]) > 0:\n",
        "        print(f\"¡Error! Hay índices inválidos en {name}.\")\n",
        "    else:\n",
        "        print(f\"Todos los índices en {name} son válidos.\")\n",
        "\n",
        "check_indices(encoder_input_sequences, \"encoder_input_sequences\", nb_words)\n",
        "check_indices(decoder_input_sequences, \"decoder_input_sequences\", len(word2idx_outputs) + 1)\n",
        "check_indices(decoder_targets, \"decoder_targets\", len(word2idx_outputs) + 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vKbhjtIwPgM"
      },
      "source": [
        "### 4 - Entrenar el modelo\n",
        "Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Definición del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "4lxRhcuNU050"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_19\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_36      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_37      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_16        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">179,900</span> │ input_layer_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_17        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">179,900</span> │ input_layer_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │ embedding_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │ embedding_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),      │            │ lstm_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],    │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]      │            │ lstm_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1807</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">233,103</span> │ lstm_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_36      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_37      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_16        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │    \u001b[38;5;34m179,900\u001b[0m │ input_layer_36[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_17        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │    \u001b[38;5;34m179,900\u001b[0m │ input_layer_37[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_16 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     │    \u001b[38;5;34m117,248\u001b[0m │ embedding_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_17 (\u001b[38;5;33mLSTM\u001b[0m)      │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m), │    \u001b[38;5;34m117,248\u001b[0m │ embedding_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),      │            │ lstm_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],    │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]      │            │ lstm_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1807\u001b[0m)  │    \u001b[38;5;34m233,103\u001b[0m │ lstm_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">827,399</span> (3.16 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m827,399\u001b[0m (3.16 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">467,599</span> (1.78 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m467,599\u001b[0m (1.78 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">359,800</span> (1.37 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m359,800\u001b[0m (1.37 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "n_units = 128\n",
        "\n",
        "# define training encoder\n",
        "encoder_inputs = Input(shape=(max_input_len,))\n",
        "\n",
        "#encoder_embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)\n",
        "\n",
        "encoder_embedding_layer = Embedding(\n",
        "          input_dim=nb_words,  # definido en el Tokenizador\n",
        "          output_dim=embed_dim,  # dimensión de los embeddings utilizados\n",
        "          input_length=max_input_len, # tamaño máximo de la secuencia de entrada\n",
        "          weights=[embedding_matrix],  # matrix de embeddings\n",
        "          trainable=False)      # marcar como layer no entrenable\n",
        "\n",
        "encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n",
        "\n",
        "encoder = LSTM(n_units, return_state=True,dropout=0.4)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# define training decoder\n",
        "decoder_inputs = Input(shape=(max_out_len,))\n",
        "#decoder_embedding_layer = Embedding(input_dim=num_words_output, output_dim=n_units, input_length=max_out_len)\n",
        "\n",
        "decoder_embedding_layer = Embedding(\n",
        "          input_dim=nb_words,  # definido en el Tokenizador\n",
        "          output_dim=embed_dim,  # dimensión de los embeddings utilizados\n",
        "          input_length=max_out_len, # tamaño máximo de la secuencia de entrada\n",
        "          weights=[embedding_matrix],  # matrix de embeddings\n",
        "          trainable=False)      # marcar como layer no entrenable\n",
        "\n",
        "decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True,dropout=0.4)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
        "\n",
        "# Dense\n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "#optimizer = Adam()learning_rate=0.0001)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define inference encoder\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Modelo solo decoder (para realizar inferencia)\n",
        "\n",
        "# define inference decoder\n",
        "decoder_state_input_h = Input(shape=(n_units,))\n",
        "decoder_state_input_c = Input(shape=(n_units,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# En cada predicción habrá una sola palabra de entrada al decoder,\n",
        "# que es la realimentación de la palabra anterior\n",
        "# por lo que hay que modificar el input shape de la layer de Embedding\n",
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4562 - loss: 4.4617"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node functional_19_1/embedding_16_1/GatherV2 defined at (most recent call last):\n  File \"c:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"c:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n\n  File \"c:\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n\n  File \"c:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_15696\\1042706293.py\", line 1, in <module>\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 392, in fit\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 481, in evaluate\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 216, in function\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 129, in multi_step_on_iterator\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 110, in one_step_on_data\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 87, in test_step\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 899, in __call__\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 182, in call\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 632, in call\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 899, in __call__\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 140, in call\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 5239, in take\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 2063, in take\n\nindices[14,8] = 1799 is not in [0, 1799)\n\t [[{{node functional_19_1/embedding_16_1/GatherV2}}]] [Op:__inference_multi_step_on_iterator_41024]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder_input_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_sequences\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_19_1/embedding_16_1/GatherV2 defined at (most recent call last):\n  File \"c:\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"c:\\Python310\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n\n  File \"c:\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n\n  File \"c:\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\marti\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_15696\\1042706293.py\", line 1, in <module>\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 392, in fit\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 481, in evaluate\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 216, in function\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 129, in multi_step_on_iterator\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 110, in one_step_on_data\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 87, in test_step\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 899, in __call__\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 182, in call\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\models\\functional.py\", line 632, in call\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py\", line 899, in __call__\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 140, in call\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 5239, in take\n\n  File \"c:\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 2063, in take\n\nindices[14,8] = 1799 is not in [0, 1799)\n\t [[{{node functional_19_1/embedding_16_1/GatherV2}}]] [Op:__inference_multi_step_on_iterator_41024]"
          ]
        }
      ],
      "source": [
        "hist = model.fit(\n",
        "    [encoder_input_sequences, decoder_input_sequences],\n",
        "    decoder_targets,\n",
        "    epochs=50,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbwn0ekDy_s2"
      },
      "source": [
        "### 5 - Inferencia\n",
        "Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
